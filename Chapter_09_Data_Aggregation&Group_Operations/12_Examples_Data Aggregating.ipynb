{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Example: Filling Missing Values with Group-specific Values\n",
    "\n",
    "When cleaning up missing data, in some cases you will filter out data observations using dropna, but in others you may want to impute (fill in) the NA values using a fixed value or some value derived form he data. fillna is the right tool to use; for example here I fill in NA values with the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Series(np.random.randn(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         NaN\n",
       "1    0.860078\n",
       "2         NaN\n",
       "3    1.303794\n",
       "4         NaN\n",
       "5    0.719013\n",
       "6         NaN\n",
       "7    0.343548\n",
       "8         NaN\n",
       "9    0.159409\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[::2] = [np.nan, np.nan, np.nan, np.nan, np.nan]\n",
    "\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2.019169\n",
       "1    0.860078\n",
       "2    2.019169\n",
       "3    1.303794\n",
       "4    2.019169\n",
       "5    0.719013\n",
       "6    2.019169\n",
       "7    0.343548\n",
       "8    2.019169\n",
       "9    0.159409\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.fillna(s.mean(0)+1.342)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you need the fill value to very by group. As you may guess, you need only group the data and use *apply* with a functiontion that calls *fillna* on each data chunk. Here is some sample data on some US states divided into eastern and weastern states:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = ['Ohio', 'New York', 'Vermont', 'Florida',\n",
    "          'Oregon', 'Nevada', 'California', 'Idaho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_key = ['East'] *4 + ['West'] * 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Series(np.arange(8), index=states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['Vermont', 'Nevada', 'Idaho']] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ohio          0.0\n",
       "New York      1.0\n",
       "Vermont       NaN\n",
       "Florida       3.0\n",
       "Oregon        4.0\n",
       "Nevada        NaN\n",
       "California    6.0\n",
       "Idaho         NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "East     4.0\n",
       "West    10.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(group_key).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "East \n",
      " Ohio        0.0\n",
      "New York    1.0\n",
      "Vermont     NaN\n",
      "Florida     3.0\n",
      "dtype: float64\n",
      "West \n",
      " Oregon        4.0\n",
      "Nevada        NaN\n",
      "California    6.0\n",
      "Idaho         NaN\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for i, j in data.groupby(group_key):\n",
    "    print(i, '\\n', j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can fill the NA values using the group means like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_mean = lambda g: g.fillna(g.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ohio          0.000000\n",
       "New York      1.000000\n",
       "Vermont       1.333333\n",
       "Florida       3.000000\n",
       "Oregon        4.000000\n",
       "Nevada        5.000000\n",
       "California    6.000000\n",
       "Idaho         5.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(group_key).apply(fill_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In another case, you might have pre-difine fill values in your code that vary by group.\n",
    "\n",
    "Since the groups have a *name* attribute set internally, we can use that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_values = {'East': .5, 'West': -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fill_func = lambda x: x.fillna(fill_values[x.name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ohio          0.0\n",
       "New York      1.0\n",
       "Vermont       0.5\n",
       "Florida       3.0\n",
       "Oregon        4.0\n",
       "Nevada       -1.0\n",
       "California    6.0\n",
       "Idaho        -1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(group_key).apply(fill_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Random Sampling and Permutation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted to draw a random sample (with or without replacement) from a large dataset for Monte Carlo simulation purposes or some other application. There are a number of wasy to perform the \"draws\"; some are much more efficient than others. One way is to select the first K elements of np.random.permutation(N), where N is the size of your complete dataset and K the desired sample size. As a more fun example, here's a way to construct a deck of English-style playing cards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hearts, Spades, Clubs, Diamonds\n",
    "\n",
    "suits = ['H','S', 'C', 'D']\n",
    "\n",
    "card_val = list(range(1, 11)) + [10] *3\n",
    "\n",
    "card_val = card_val * 4\n",
    "\n",
    "base_names = ['A'] + list(range(2, 11)) + ['J', 'K','Q']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cards = []\n",
    "\n",
    "for suits in ['H', 'S', 'C', 'D']:\n",
    "    cards.extend(str(num) + suits for num in base_names)\n",
    "\n",
    "deck = Series(card_val, index = cards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a Series of length 52 whose index contains card names and values are the ones used in blackjack and other games (to keep things simple, I just let the ace be 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AH      1\n",
       "2H      2\n",
       "3H      3\n",
       "4H      4\n",
       "5H      5\n",
       "6H      6\n",
       "7H      7\n",
       "8H      8\n",
       "9H      9\n",
       "10H    10\n",
       "JH     10\n",
       "KH     10\n",
       "QH     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deck[:13]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, based on what I said above, drawing a hand of 5 cards from the desk could be written as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw (deck, n = 4):\n",
    "    return deck.take(np.random.permutation(len(deck))[:n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4S    4\n",
       "5S    5\n",
       "3C    3\n",
       "9S    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw(deck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you wanted two random cards from each suit. Because the suit is the last character of each card name, we can group based on this and use apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_suit = lambda card: card[-1] #last letter is suit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C  2C      2\n",
       "   6C      6\n",
       "D  KD     10\n",
       "   4D      4\n",
       "H  7H      7\n",
       "   10H    10\n",
       "S  3S      3\n",
       "   QS     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deck.groupby(get_suit).apply(draw, n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AC      1\n",
       "QC     10\n",
       "10D    10\n",
       "AD      1\n",
       "10H    10\n",
       "QH     10\n",
       "QS     10\n",
       "8S      8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alternatively\n",
    "\n",
    "deck.groupby(get_suit, group_keys= False).apply(draw, n = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Group Weighted Average and Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under the split- apply- combine paradigm of *groupby*, operations between columns in a DataFrame or two Series, such a group weighted average, become a routine affair. As an example, take this dataset containing group keys, values and some weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame({'category': ['a', 'a','a', 'a','b','b','b','b'],\n",
    "                'data': np.random.randn(8),\n",
    "                'weights': np.arange(8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>data</th>\n",
       "      <th>weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0.527354</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>-1.613679</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0.671570</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>0.084891</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>-1.991321</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b</td>\n",
       "      <td>0.458878</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b</td>\n",
       "      <td>-0.010845</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b</td>\n",
       "      <td>-1.237221</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category      data  weights\n",
       "0        a  0.527354        0\n",
       "1        a -1.613679        1\n",
       "2        a  0.671570        2\n",
       "3        a  0.084891        3\n",
       "4        b -1.991321        4\n",
       "5        b  0.458878        5\n",
       "6        b -0.010845        6\n",
       "7        b -1.237221        7"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The group weighted average by *category* would then be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_wavg = lambda g: np.average(g['data'], weights = g['weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "a   -0.002644\n",
       "b   -0.654387\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped.apply(get_wavg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AS a less trivial example, consider a data set from Yahoo! Finance containing end of day prices for a few stocks and the S&P 500 index (the SPX ticker):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "close_px = pd.read_csv('../../CSV Files/O_Reilly/ch09/stock_px.csv',\n",
    "            parse_dates= True, index_col= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2214 entries, 2003-01-02 to 2011-10-14\n",
      "Data columns (total 4 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AAPL    2214 non-null   float64\n",
      " 1   MSFT    2214 non-null   float64\n",
      " 2   XOM     2214 non-null   float64\n",
      " 3   SPX     2214 non-null   float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 86.5 KB\n"
     ]
    }
   ],
   "source": [
    "close_px.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One Tesk of interest might be to compute a DataFrame consisting of the yearly correlations of daily returns (computed form percent changes) with SPX. Here is one way to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>XOM</th>\n",
       "      <th>SPX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-03</th>\n",
       "      <td>0.006757</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>-0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-06</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017975</td>\n",
       "      <td>0.024624</td>\n",
       "      <td>0.022474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-07</th>\n",
       "      <td>-0.002685</td>\n",
       "      <td>0.019052</td>\n",
       "      <td>-0.033712</td>\n",
       "      <td>-0.006545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-08</th>\n",
       "      <td>-0.020188</td>\n",
       "      <td>-0.028272</td>\n",
       "      <td>-0.004145</td>\n",
       "      <td>-0.014086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-09</th>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.029094</td>\n",
       "      <td>0.021159</td>\n",
       "      <td>0.019386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-10</th>\n",
       "      <td>0.051406</td>\n",
       "      <td>0.026286</td>\n",
       "      <td>0.036977</td>\n",
       "      <td>0.034125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-11</th>\n",
       "      <td>0.029526</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-12</th>\n",
       "      <td>0.004747</td>\n",
       "      <td>-0.001481</td>\n",
       "      <td>0.011669</td>\n",
       "      <td>0.009795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-13</th>\n",
       "      <td>0.015515</td>\n",
       "      <td>0.008160</td>\n",
       "      <td>-0.010238</td>\n",
       "      <td>-0.002974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-10-14</th>\n",
       "      <td>0.033225</td>\n",
       "      <td>0.003311</td>\n",
       "      <td>0.022784</td>\n",
       "      <td>0.017380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2213 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL      MSFT       XOM       SPX\n",
       "2003-01-03  0.006757  0.001421  0.000684 -0.000484\n",
       "2003-01-06  0.000000  0.017975  0.024624  0.022474\n",
       "2003-01-07 -0.002685  0.019052 -0.033712 -0.006545\n",
       "2003-01-08 -0.020188 -0.028272 -0.004145 -0.014086\n",
       "2003-01-09  0.008242  0.029094  0.021159  0.019386\n",
       "...              ...       ...       ...       ...\n",
       "2011-10-10  0.051406  0.026286  0.036977  0.034125\n",
       "2011-10-11  0.029526  0.002227 -0.000131  0.000544\n",
       "2011-10-12  0.004747 -0.001481  0.011669  0.009795\n",
       "2011-10-13  0.015515  0.008160 -0.010238 -0.002974\n",
       "2011-10-14  0.033225  0.003311  0.022784  0.017380\n",
       "\n",
       "[2213 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rets = close_px.pct_change().dropna()\n",
    "\n",
    "rets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.<lambda>(x)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spx_corr = lambda x: x.corrwith(x['SPX'])\n",
    "\n",
    "spx_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x000002BBBB9AD6C0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_year = rets.groupby(lambda x: x.year)\n",
    "\n",
    "by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AAPL</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>XOM</th>\n",
       "      <th>SPX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>0.541124</td>\n",
       "      <td>0.745174</td>\n",
       "      <td>0.661265</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <td>0.374283</td>\n",
       "      <td>0.588531</td>\n",
       "      <td>0.557742</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <td>0.467540</td>\n",
       "      <td>0.562374</td>\n",
       "      <td>0.631010</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <td>0.428267</td>\n",
       "      <td>0.406126</td>\n",
       "      <td>0.518514</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>0.508118</td>\n",
       "      <td>0.658770</td>\n",
       "      <td>0.786264</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>0.681434</td>\n",
       "      <td>0.804626</td>\n",
       "      <td>0.828303</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>0.707103</td>\n",
       "      <td>0.654902</td>\n",
       "      <td>0.797921</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>0.710105</td>\n",
       "      <td>0.730118</td>\n",
       "      <td>0.839057</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0.691931</td>\n",
       "      <td>0.800996</td>\n",
       "      <td>0.859975</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AAPL      MSFT       XOM  SPX\n",
       "2003  0.541124  0.745174  0.661265  1.0\n",
       "2004  0.374283  0.588531  0.557742  1.0\n",
       "2005  0.467540  0.562374  0.631010  1.0\n",
       "2006  0.428267  0.406126  0.518514  1.0\n",
       "2007  0.508118  0.658770  0.786264  1.0\n",
       "2008  0.681434  0.804626  0.828303  1.0\n",
       "2009  0.707103  0.654902  0.797921  1.0\n",
       "2010  0.710105  0.730118  0.839057  1.0\n",
       "2011  0.691931  0.800996  0.859975  1.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_year.apply(spx_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is, of course, nothing to stop you form computing inter-column correlations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2003    0.480868\n",
       "2004    0.259024\n",
       "2005    0.300093\n",
       "2006    0.161735\n",
       "2007    0.417738\n",
       "2008    0.611901\n",
       "2009    0.432738\n",
       "2010    0.571946\n",
       "2011    0.581987\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Annual correlation of Apple with Microsoft\n",
    "\n",
    "by_year.apply(lambda i: i['AAPL'].corr(i['MSFT']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Group-Wise Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the same vein as the previous example, you can use *groupby* to perform more complex group-wise statistical analysis, as long the function returns a pandas object or scalar value. For example, I can define the following *reggress* function (using the *statsmodels* econometrics library) whic executes an ordinary least squares (OLS) regression on each chunk of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "def regress(data, yvar, xvars):\n",
    "    Y = data[yvar]\n",
    "    X = data[xvars]\n",
    "    X['intercept'] = 1\n",
    "    result = sm.OLS(X, Y).fit()\n",
    "    return result.params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to run a yearly linear regression of AAPL on SPX returns, I execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.246326</td>\n",
       "      <td>3.175114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.101922</td>\n",
       "      <td>7.040350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2005</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.122066</td>\n",
       "      <td>5.732395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.112147</td>\n",
       "      <td>1.616610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.211554</td>\n",
       "      <td>6.365622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.480320</td>\n",
       "      <td>-1.965627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.559087</td>\n",
       "      <td>8.135493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.476900</td>\n",
       "      <td>6.396784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <th>AAPL</th>\n",
       "      <td>0.588582</td>\n",
       "      <td>5.437102</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0         1\n",
       "2003 AAPL  0.246326  3.175114\n",
       "2004 AAPL  0.101922  7.040350\n",
       "2005 AAPL  0.122066  5.732395\n",
       "2006 AAPL  0.112147  1.616610\n",
       "2007 AAPL  0.211554  6.365622\n",
       "2008 AAPL  0.480320 -1.965627\n",
       "2009 AAPL  0.559087  8.135493\n",
       "2010 AAPL  0.476900  6.396784\n",
       "2011 AAPL  0.588582  5.437102"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "by_year.apply(regress, 'AAPL', ['SPX'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ffea71f7b71092eabe4cd0b8ca5f97eab7e23656a5f6413a198e81db1d0ce6b2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
